{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Model for 1D\n",
    "## Develop 1D Convolutional Neural Network\n",
    "\n",
    "Reference: https://machinelearningmastery.com/cnn-models-for-human-activity-recognition-time-series-classification/\n",
    "\n",
    "In this section, we will develop a one-dimensional convolutional neural network model (1D CNN) for the human activity recognition dataset.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutional neural network models were developed for image classification problems, where the model learns an internal representation of a two-dimensional input, in a process referred to as feature learning.\n",
    "\n",
    "This same process can be harnessed on one-dimensional sequences of data, such as in the case of acceleration and gyroscopic data for human activity recognition. The model learns to extract features from sequences of observations and how to map the internal features to different activity types."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9 data points being the body acceleration, body gyroscopic data (i.e. angular velocity) and hte total acceleartion in all 3 directions. (3x3)\n",
    "\n",
    "Further, each series of data has been partitioned into overlapping windows of 2.65 seconds of data, or 128 time steps. These windows of data correspond to the windows of engineered features (rows) in the previous section\n",
    "\n",
    "and we have 7352 such example time series."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In terms of prediciton we have 6 possible outputs detailed under activity_labels.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnn model\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import dstack\n",
    "from pandas import read_csv\n",
    "from matplotlib import pyplot\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers import MaxPooling1D\n",
    "# removed .convolutional from the above 2 imports\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load a single file as a numpy array\n",
    "def load_file(filepath):\n",
    "\tdataframe = read_csv(filepath, header=None, delim_whitespace=True)\n",
    "\treturn dataframe.values\n",
    "\n",
    "# load a list of files and return as a 3d numpy array\n",
    "def load_group(filenames, prefix=''):\n",
    "\tloaded = list()\n",
    "\tfor name in filenames:\n",
    "\t\tdata = load_file(prefix + name)\n",
    "\t\tloaded.append(data)\n",
    "\t# stack group so that features are the 3rd dimension\n",
    "\tloaded = dstack(loaded)\n",
    "\treturn loaded\n",
    "\n",
    "# load a dataset group, such as train or test\n",
    "def load_dataset_group(group, prefix='./'):\n",
    "\tfilepath = prefix + group + '/InertialSignals/'\n",
    "\t# load all 9 files as a single array\n",
    "\tfilenames = list()\n",
    "\t# total acceleration\n",
    "\tfilenames += ['total_acc_x_'+group+'.txt', 'total_acc_y_'+group+'.txt', 'total_acc_z_'+group+'.txt']\n",
    "\t# body acceleration\n",
    "\tfilenames += ['body_acc_x_'+group+'.txt', 'body_acc_y_'+group+'.txt', 'body_acc_z_'+group+'.txt']\n",
    "\t# body gyroscope\n",
    "\tfilenames += ['body_gyro_x_'+group+'.txt', 'body_gyro_y_'+group+'.txt', 'body_gyro_z_'+group+'.txt']\n",
    "\t# load input data\n",
    "\tX = load_group(filenames, filepath)\n",
    "\t# load class output\n",
    "\ty = load_file(prefix + group + '/y_'+group+'.txt')\n",
    "\treturn X, y\n",
    "\n",
    "# load the dataset, returns train and test X and y elements\n",
    "def load_dataset(prefix=''):\n",
    "\t# load all train\n",
    "\ttrainX, trainy = load_dataset_group('train', prefix + 'HARDataset/')\n",
    "\t# load all test\n",
    "\ttestX, testy = load_dataset_group('test', prefix + 'HARDataset/')\n",
    "\t# zero-offset class values\n",
    "\ttrainy = trainy - 1\n",
    "\ttesty = testy - 1\n",
    "\t# one hot encode y\n",
    "\ttrainy = to_categorical(trainy)\n",
    "\ttesty = to_categorical(testy)\n",
    "\treturn trainX, trainy, testX, testy\n",
    "\n",
    "# fit and evaluate a model\n",
    "def evaluate_model(trainX, trainy, testX, testy):\n",
    "\tverbose, epochs, batch_size = 0, 10, 32\n",
    "\tn_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(n_timesteps,n_features)))\n",
    "\tmodel.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "\tmodel.add(Dropout(0.5))\n",
    "\tmodel.add(MaxPooling1D(pool_size=2))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(100, activation='relu'))\n",
    "\tmodel.add(Dense(n_outputs, activation='softmax'))\n",
    "\t#output classification\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\t# fit network\n",
    "\tmodel.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "\t# evaluate model\n",
    "\t_, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=0)\n",
    "\treturn accuracy\n",
    "\n",
    "# summarize scores\n",
    "def summarize_results(scores):\n",
    "\tprint(scores)\n",
    "\tm, s = mean(scores), std(scores)\n",
    "\tprint('Accuracy: %.3f%% (+/-%.3f)' % (m, s))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 9)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = trainX[0]\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.012817</td>\n",
       "      <td>-0.123217</td>\n",
       "      <td>0.102934</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.010767</td>\n",
       "      <td>0.055561</td>\n",
       "      <td>0.030191</td>\n",
       "      <td>0.066014</td>\n",
       "      <td>0.022859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.022833</td>\n",
       "      <td>-0.126876</td>\n",
       "      <td>0.105687</td>\n",
       "      <td>0.010139</td>\n",
       "      <td>0.006579</td>\n",
       "      <td>0.055125</td>\n",
       "      <td>0.043711</td>\n",
       "      <td>0.042699</td>\n",
       "      <td>0.010316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.022028</td>\n",
       "      <td>-0.124004</td>\n",
       "      <td>0.102102</td>\n",
       "      <td>0.009276</td>\n",
       "      <td>0.008929</td>\n",
       "      <td>0.048405</td>\n",
       "      <td>0.035688</td>\n",
       "      <td>0.074850</td>\n",
       "      <td>0.013250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.017877</td>\n",
       "      <td>-0.124928</td>\n",
       "      <td>0.106553</td>\n",
       "      <td>0.005066</td>\n",
       "      <td>0.007489</td>\n",
       "      <td>0.049775</td>\n",
       "      <td>0.040402</td>\n",
       "      <td>0.057320</td>\n",
       "      <td>0.017751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.023680</td>\n",
       "      <td>-0.125767</td>\n",
       "      <td>0.102814</td>\n",
       "      <td>0.010810</td>\n",
       "      <td>0.006141</td>\n",
       "      <td>0.043013</td>\n",
       "      <td>0.047097</td>\n",
       "      <td>0.052343</td>\n",
       "      <td>0.002553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>1.019815</td>\n",
       "      <td>-0.127010</td>\n",
       "      <td>0.094843</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>-0.002929</td>\n",
       "      <td>-0.003412</td>\n",
       "      <td>0.025197</td>\n",
       "      <td>-0.005166</td>\n",
       "      <td>0.007355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>1.019290</td>\n",
       "      <td>-0.126185</td>\n",
       "      <td>0.098350</td>\n",
       "      <td>-0.000300</td>\n",
       "      <td>-0.002023</td>\n",
       "      <td>0.000359</td>\n",
       "      <td>0.032328</td>\n",
       "      <td>-0.001298</td>\n",
       "      <td>0.002669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>1.018445</td>\n",
       "      <td>-0.124070</td>\n",
       "      <td>0.100385</td>\n",
       "      <td>-0.001147</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>0.002648</td>\n",
       "      <td>0.039852</td>\n",
       "      <td>0.001909</td>\n",
       "      <td>-0.002170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>1.019372</td>\n",
       "      <td>-0.122745</td>\n",
       "      <td>0.099874</td>\n",
       "      <td>-0.000222</td>\n",
       "      <td>0.001574</td>\n",
       "      <td>0.002381</td>\n",
       "      <td>0.037449</td>\n",
       "      <td>-0.000080</td>\n",
       "      <td>-0.005643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>1.021171</td>\n",
       "      <td>-0.121326</td>\n",
       "      <td>0.094987</td>\n",
       "      <td>0.001576</td>\n",
       "      <td>0.003070</td>\n",
       "      <td>-0.002270</td>\n",
       "      <td>0.028818</td>\n",
       "      <td>-0.000038</td>\n",
       "      <td>-0.001446</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>128 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "0    1.012817 -0.123217  0.102934  0.000181  0.010767  0.055561  0.030191   \n",
       "1    1.022833 -0.126876  0.105687  0.010139  0.006579  0.055125  0.043711   \n",
       "2    1.022028 -0.124004  0.102102  0.009276  0.008929  0.048405  0.035688   \n",
       "3    1.017877 -0.124928  0.106553  0.005066  0.007489  0.049775  0.040402   \n",
       "4    1.023680 -0.125767  0.102814  0.010810  0.006141  0.043013  0.047097   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "123  1.019815 -0.127010  0.094843  0.000228 -0.002929 -0.003412  0.025197   \n",
       "124  1.019290 -0.126185  0.098350 -0.000300 -0.002023  0.000359  0.032328   \n",
       "125  1.018445 -0.124070  0.100385 -0.001147  0.000171  0.002648  0.039852   \n",
       "126  1.019372 -0.122745  0.099874 -0.000222  0.001574  0.002381  0.037449   \n",
       "127  1.021171 -0.121326  0.094987  0.001576  0.003070 -0.002270  0.028818   \n",
       "\n",
       "            7         8  \n",
       "0    0.066014  0.022859  \n",
       "1    0.042699  0.010316  \n",
       "2    0.074850  0.013250  \n",
       "3    0.057320  0.017751  \n",
       "4    0.052343  0.002553  \n",
       "..        ...       ...  \n",
       "123 -0.005166  0.007355  \n",
       "124 -0.001298  0.002669  \n",
       "125  0.001909 -0.002170  \n",
       "126 -0.000080 -0.005643  \n",
       "127 -0.000038 -0.001446  \n",
       "\n",
       "[128 rows x 9 columns]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "x = pd.DataFrame(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run an experiment\n",
    "def run_experiment(repeats=10):\n",
    "\t# load data\n",
    "\ttrainX, trainy, testX, testy = load_dataset()\n",
    "\t# repeat experiment\n",
    "\tscores = list()\n",
    "\tprint('trainy and trainx shapes', trainy.shape, trainX.shape)\n",
    "\tfor r in range(repeats):\n",
    "\t\tscore = evaluate_model(trainX, trainy, testX, testy)\n",
    "\t\tscore = score * 100.0\n",
    "\t\tprint('>#%d: %.3f' % (r+1, score))\n",
    "\t\tscores.append(score)\n",
    "\t# summarize results\n",
    "\tsummarize_results(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2n/957lm2v90hldklvnq4r45g4c0000gn/T/ipykernel_14645/3654877324.py:3: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  dataframe = read_csv(filepath, header=None, delim_whitespace=True)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'HARDataset/train/InertialSignals/total_acc_x_train.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[183], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m repeats \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m\n\u001b[0;32m----> 2\u001b[0m trainX, trainy, testX, testy \u001b[39m=\u001b[39m load_dataset()\n",
      "Cell \u001b[0;32mIn[179], line 36\u001b[0m, in \u001b[0;36mload_dataset\u001b[0;34m(prefix)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_dataset\u001b[39m(prefix\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m     35\u001b[0m \t\u001b[39m# load all train\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m \ttrainX, trainy \u001b[39m=\u001b[39m load_dataset_group(\u001b[39m'\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m'\u001b[39;49m, prefix \u001b[39m+\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mHARDataset/\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     37\u001b[0m \t\u001b[39m# load all test\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \ttestX, testy \u001b[39m=\u001b[39m load_dataset_group(\u001b[39m'\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m'\u001b[39m, prefix \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39mHARDataset/\u001b[39m\u001b[39m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[179], line 28\u001b[0m, in \u001b[0;36mload_dataset_group\u001b[0;34m(group, prefix)\u001b[0m\n\u001b[1;32m     26\u001b[0m filenames \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mbody_gyro_x_\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39mgroup\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.txt\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mbody_gyro_y_\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39mgroup\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.txt\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mbody_gyro_z_\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39mgroup\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.txt\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     27\u001b[0m \u001b[39m# load input data\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m X \u001b[39m=\u001b[39m load_group(filenames, filepath)\n\u001b[1;32m     29\u001b[0m \u001b[39m# load class output\u001b[39;00m\n\u001b[1;32m     30\u001b[0m y \u001b[39m=\u001b[39m load_file(prefix \u001b[39m+\u001b[39m group \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/y_\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39mgroup\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.txt\u001b[39m\u001b[39m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[179], line 10\u001b[0m, in \u001b[0;36mload_group\u001b[0;34m(filenames, prefix)\u001b[0m\n\u001b[1;32m      8\u001b[0m loaded \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m()\n\u001b[1;32m      9\u001b[0m \u001b[39mfor\u001b[39;00m name \u001b[39min\u001b[39;00m filenames:\n\u001b[0;32m---> 10\u001b[0m \tdata \u001b[39m=\u001b[39m load_file(prefix \u001b[39m+\u001b[39;49m name)\n\u001b[1;32m     11\u001b[0m \tloaded\u001b[39m.\u001b[39mappend(data)\n\u001b[1;32m     12\u001b[0m \u001b[39m# stack group so that features are the 3rd dimension\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[179], line 3\u001b[0m, in \u001b[0;36mload_file\u001b[0;34m(filepath)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_file\u001b[39m(filepath):\n\u001b[0;32m----> 3\u001b[0m \tdataframe \u001b[39m=\u001b[39m read_csv(filepath, header\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, delim_whitespace\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m      4\u001b[0m \t\u001b[39mreturn\u001b[39;00m dataframe\u001b[39m.\u001b[39mvalues\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    622\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[1;32m   1881\u001b[0m     f,\n\u001b[1;32m   1882\u001b[0m     mode,\n\u001b[1;32m   1883\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1884\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1885\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   1886\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   1887\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1888\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1889\u001b[0m )\n\u001b[1;32m   1890\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[39m.\u001b[39mmode,\n\u001b[1;32m    876\u001b[0m             encoding\u001b[39m=\u001b[39mioargs\u001b[39m.\u001b[39mencoding,\n\u001b[1;32m    877\u001b[0m             errors\u001b[39m=\u001b[39merrors,\n\u001b[1;32m    878\u001b[0m             newline\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'HARDataset/train/InertialSignals/total_acc_x_train.txt'"
     ]
    }
   ],
   "source": [
    "repeats = 10\n",
    "trainX, trainy, testX, testy = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7352, 128, 9)\n"
     ]
    }
   ],
   "source": [
    "# pd.DataFrame(trainX).head()\n",
    "print(trainX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">#1: 90.465\n",
      ">#2: 91.958\n",
      ">#3: 86.257\n",
      ">#4: 91.347\n",
      ">#5: 88.768\n",
      ">#6: 91.008\n",
      ">#7: 89.990\n",
      ">#8: 91.381\n",
      ">#9: 91.686\n",
      ">#10: 88.056\n",
      "[90.46487808227539, 91.95792078971863, 86.25721335411072, 91.34713411331177, 88.76823782920837, 91.00780487060547, 89.98982310295105, 91.3810670375824, 91.68646335601807, 88.05565237998962]\n",
      "Accuracy: 90.092% (+/-1.757)\n"
     ]
    }
   ],
   "source": [
    "scores = list()\n",
    "for r in range(repeats):\n",
    "    score = evaluate_model(trainX, trainy, testX, testy)\n",
    "    score = score * 100.0\n",
    "    print('>#%d: %.3f' % (r+1, score))\n",
    "    scores.append(score)\n",
    "# summarize results\n",
    "summarize_results(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the experiment\n",
    "# run_experiment()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
