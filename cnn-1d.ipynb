{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Model for 1D\n",
    "## Develop 1D Convolutional Neural Network"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: https://machinelearningmastery.com/cnn-models-for-human-activity-recognition-time-series-classification/\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by talking about what exactly is convolution, in particular convolution in 1D\n",
    "\n",
    "We define an input 1d column matrix called as feature vector\n",
    "and another column matrix filter/weights. \n",
    "\n",
    "The result is another column matrix we define it to be Feature Map.\n",
    "\n",
    "For each element fm_i, in feature map, at index i, we can write \n",
    "\n",
    "fm_i = sum ( fv_j * w_k )\n",
    "in shorter terms fm = fv * w (convolution)\n",
    "\n",
    "j varying over i and i + w.size\n",
    "and \n",
    "k varying over 0 and w.size\n",
    "\n",
    "This elementarily defines convolution of 2 column matrices, that is the feature vector and weights.\n",
    "This defines single layer convolution, that is a non deep CNN.\n",
    "\n",
    "However if we talk about multiple layers we take the feature map of one layer \n",
    "as the feature vector for the next layer and a maybe different filter/weights \n",
    "column vector. The same can go on for a few layers.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alternative text](convolution.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference for explanation \n",
    "https://www.youtube.com/watch?v=yd_j_zdLDWs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we now talk about what has been implemented, that is CNN to do activity recognition"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idea is to do activity recognition \n",
    "output to be given as a number bwn 1-6 denoting \n",
    "\n",
    "1 WALKING\n",
    "\n",
    "2 WALKING_UPSTAIRS\n",
    "\n",
    "3 WALKING_DOWNSTAIRS\n",
    "\n",
    "4 SITTING\n",
    "\n",
    "5 STANDING\n",
    "\n",
    "6 LAYING"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 9 inputs, that is features, body acceleration in all 3 directions, body angular velocity in all 3 directions and the total acceleration in all 3 directions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further, each series of data has been partitioned into overlapping windows of 2.65 seconds of data, or 128 time steps\n",
    "and we have 7352 such example time series."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correspondingly we get the result of type of activity being done, as described by the above 6 actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnn model\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import dstack\n",
    "from pandas import read_csv\n",
    "from matplotlib import pyplot\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers import MaxPooling1D\n",
    "# removed .convolutional from the above 2 imports\n",
    "from keras.utils import to_categorical\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a list of files and return as a 3d numpy array\n",
    "def load_group(filenames, prefix=''):\n",
    "\tloaded = list()\n",
    "\tfor name in filenames:\n",
    "\t\tdataframe = read_csv((prefix + name), header = None, sep='\\s+')\n",
    "\t\tdata = dataframe.values\n",
    "\t\tloaded.append(data)\n",
    "\t# stack group so that features are the 3rd dimension\n",
    "\tloaded = dstack(loaded)\n",
    "\treturn loaded\n",
    "\n",
    "# load a dataset group, such as train or test\n",
    "def load_dataset_group(group, prefix='./'):\n",
    "\tfilepath = prefix + group + '/InertialSignals/'\n",
    "\tfilenames = list()\n",
    "\t# total acceleration\n",
    "\tfilenames += ['total_acc_x_'+group+'.txt', 'total_acc_y_'+group+'.txt', 'total_acc_z_'+group+'.txt']\n",
    "\t# body acceleration\n",
    "\tfilenames += ['body_acc_x_'+group+'.txt', 'body_acc_y_'+group+'.txt', 'body_acc_z_'+group+'.txt']\n",
    "\t# body gyroscope\n",
    "\tfilenames += ['body_gyro_x_'+group+'.txt', 'body_gyro_y_'+group+'.txt', 'body_gyro_z_'+group+'.txt']\n",
    "\t# load input data\n",
    "\tX = load_group(filenames, filepath)\n",
    "\tprint('filenames', filenames)\n",
    "\t# load class output\n",
    "\ty_dataframe = read_csv((prefix + group + '/y_'+group+'.txt'), header = None, sep='\\s+')\n",
    "\ty = y_dataframe.values\n",
    "\treturn X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset, returns train and test X and y elements\n",
    "def load_dataset(prefix=''):\n",
    "\t# load all train\n",
    "\ttrainX, trainy = load_dataset_group('train', prefix + 'HARDataset/')\n",
    "\t# load all test\n",
    "\ttestX, testy = load_dataset_group('test', prefix + 'HARDataset/')\n",
    "\t# zero-offset class values\n",
    "\ttrainy = trainy - 1\n",
    "\ttesty = testy - 1\n",
    "\t# one hot encode y\n",
    "\ttrainy = to_categorical(trainy)\n",
    "\ttesty = to_categorical(testy)\n",
    "\treturn trainX, trainy, testX, testy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filenames ['total_acc_x_train.txt', 'total_acc_y_train.txt', 'total_acc_z_train.txt', 'body_acc_x_train.txt', 'body_acc_y_train.txt', 'body_acc_z_train.txt', 'body_gyro_x_train.txt', 'body_gyro_y_train.txt', 'body_gyro_z_train.txt']\n",
      "filenames ['total_acc_x_test.txt', 'total_acc_y_test.txt', 'total_acc_z_test.txt', 'body_acc_x_test.txt', 'body_acc_y_test.txt', 'body_acc_z_test.txt', 'body_gyro_x_test.txt', 'body_gyro_y_test.txt', 'body_gyro_z_test.txt']\n"
     ]
    }
   ],
   "source": [
    "scores = list()\n",
    "repeats = 5\n",
    "# TODO: change repeats to 10 while submitting\n",
    "trainX, trainy, testX, testy = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit and evaluate a model\n",
    "def evaluate_model(trainX, trainy, testX, testy):\n",
    "\tverbose, epochs, batch_size = 0, 10, 32\n",
    "\tn_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
    "\tprint(n_timesteps, n_features, n_outputs)\n",
    "\tmodel = Sequential()\n",
    "\t# 2 Layer Neural Networks\n",
    "\tmodel.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(n_timesteps,n_features)))\n",
    "\tmodel.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "\tmodel.add(Dropout(0.5))\n",
    "\tmodel.add(MaxPooling1D(pool_size=2))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(100, activation='relu'))\n",
    "\tmodel.add(Dense(n_outputs, activation='softmax'))\n",
    "\t#output classification\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\t# fit network\n",
    "\tmodel.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "\t# evaluate model\n",
    "\t_, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=0)\n",
    "\treturn accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128 9 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">#1: 90.940\n",
      "128 9 6\n",
      ">#2: 91.313\n",
      "128 9 6\n",
      ">#3: 91.619\n",
      "128 9 6\n",
      ">#4: 90.702\n",
      "128 9 6\n",
      ">#5: 91.076\n",
      "[90.93993902206421, 91.31320118904114, 91.6185975074768, 90.7024085521698, 91.07567071914673]\n",
      "Accuracy: 91.130% (+/-0.314)\n"
     ]
    }
   ],
   "source": [
    "for r in range(repeats):\n",
    "    if(r == 0):\n",
    "        df_trainX = trainX\n",
    "        df_trainY = trainy\n",
    "        df_testX = testX\n",
    "        df_testY = testy\n",
    "    score = evaluate_model(trainX, trainy, testX, testy)\n",
    "    score = score * 100.0\n",
    "    print('>#%d: %.3f' % (r+1, score))\n",
    "    scores.append(score)\n",
    "# summarize results\n",
    "print(scores)\n",
    "m, s = mean(scores), std(scores)\n",
    "print('Accuracy: %.3f%% (+/-%.3f)' % (m, s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BAD Practice to have same names!\n",
    "df_trainX = pd.DataFrame(df_trainX[0])\n",
    "df_trainY = pd.DataFrame(df_trainY[0])\n",
    "df_testX = pd.DataFrame(df_testX[0])\n",
    "df_testY = pd.DataFrame(df_testY[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_acc_x_train</th>\n",
       "      <th>total_acc_y_train</th>\n",
       "      <th>total_acc_z_train</th>\n",
       "      <th>body_acc_x_train</th>\n",
       "      <th>body_acc_y_train</th>\n",
       "      <th>body_acc_z_train</th>\n",
       "      <th>body_gyro_x_train</th>\n",
       "      <th>body_gyro_y_train</th>\n",
       "      <th>body_gyro_z_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.012817</td>\n",
       "      <td>-0.123217</td>\n",
       "      <td>0.102934</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.010767</td>\n",
       "      <td>0.055561</td>\n",
       "      <td>0.030191</td>\n",
       "      <td>0.066014</td>\n",
       "      <td>0.022859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.022833</td>\n",
       "      <td>-0.126876</td>\n",
       "      <td>0.105687</td>\n",
       "      <td>0.010139</td>\n",
       "      <td>0.006579</td>\n",
       "      <td>0.055125</td>\n",
       "      <td>0.043711</td>\n",
       "      <td>0.042699</td>\n",
       "      <td>0.010316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.022028</td>\n",
       "      <td>-0.124004</td>\n",
       "      <td>0.102102</td>\n",
       "      <td>0.009276</td>\n",
       "      <td>0.008929</td>\n",
       "      <td>0.048405</td>\n",
       "      <td>0.035688</td>\n",
       "      <td>0.074850</td>\n",
       "      <td>0.013250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.017877</td>\n",
       "      <td>-0.124928</td>\n",
       "      <td>0.106553</td>\n",
       "      <td>0.005066</td>\n",
       "      <td>0.007489</td>\n",
       "      <td>0.049775</td>\n",
       "      <td>0.040402</td>\n",
       "      <td>0.057320</td>\n",
       "      <td>0.017751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.023680</td>\n",
       "      <td>-0.125767</td>\n",
       "      <td>0.102814</td>\n",
       "      <td>0.010810</td>\n",
       "      <td>0.006141</td>\n",
       "      <td>0.043013</td>\n",
       "      <td>0.047097</td>\n",
       "      <td>0.052343</td>\n",
       "      <td>0.002553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>1.019815</td>\n",
       "      <td>-0.127010</td>\n",
       "      <td>0.094843</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>-0.002929</td>\n",
       "      <td>-0.003412</td>\n",
       "      <td>0.025197</td>\n",
       "      <td>-0.005166</td>\n",
       "      <td>0.007355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>1.019290</td>\n",
       "      <td>-0.126185</td>\n",
       "      <td>0.098350</td>\n",
       "      <td>-0.000300</td>\n",
       "      <td>-0.002023</td>\n",
       "      <td>0.000359</td>\n",
       "      <td>0.032328</td>\n",
       "      <td>-0.001298</td>\n",
       "      <td>0.002669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>1.018445</td>\n",
       "      <td>-0.124070</td>\n",
       "      <td>0.100385</td>\n",
       "      <td>-0.001147</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>0.002648</td>\n",
       "      <td>0.039852</td>\n",
       "      <td>0.001909</td>\n",
       "      <td>-0.002170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>1.019372</td>\n",
       "      <td>-0.122745</td>\n",
       "      <td>0.099874</td>\n",
       "      <td>-0.000222</td>\n",
       "      <td>0.001574</td>\n",
       "      <td>0.002381</td>\n",
       "      <td>0.037449</td>\n",
       "      <td>-0.000080</td>\n",
       "      <td>-0.005643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>1.021171</td>\n",
       "      <td>-0.121326</td>\n",
       "      <td>0.094987</td>\n",
       "      <td>0.001576</td>\n",
       "      <td>0.003070</td>\n",
       "      <td>-0.002270</td>\n",
       "      <td>0.028818</td>\n",
       "      <td>-0.000038</td>\n",
       "      <td>-0.001446</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>128 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     total_acc_x_train  total_acc_y_train  total_acc_z_train  \\\n",
       "0             1.012817          -0.123217           0.102934   \n",
       "1             1.022833          -0.126876           0.105687   \n",
       "2             1.022028          -0.124004           0.102102   \n",
       "3             1.017877          -0.124928           0.106553   \n",
       "4             1.023680          -0.125767           0.102814   \n",
       "..                 ...                ...                ...   \n",
       "123           1.019815          -0.127010           0.094843   \n",
       "124           1.019290          -0.126185           0.098350   \n",
       "125           1.018445          -0.124070           0.100385   \n",
       "126           1.019372          -0.122745           0.099874   \n",
       "127           1.021171          -0.121326           0.094987   \n",
       "\n",
       "     body_acc_x_train  body_acc_y_train  body_acc_z_train  body_gyro_x_train  \\\n",
       "0            0.000181          0.010767          0.055561           0.030191   \n",
       "1            0.010139          0.006579          0.055125           0.043711   \n",
       "2            0.009276          0.008929          0.048405           0.035688   \n",
       "3            0.005066          0.007489          0.049775           0.040402   \n",
       "4            0.010810          0.006141          0.043013           0.047097   \n",
       "..                ...               ...               ...                ...   \n",
       "123          0.000228         -0.002929         -0.003412           0.025197   \n",
       "124         -0.000300         -0.002023          0.000359           0.032328   \n",
       "125         -0.001147          0.000171          0.002648           0.039852   \n",
       "126         -0.000222          0.001574          0.002381           0.037449   \n",
       "127          0.001576          0.003070         -0.002270           0.028818   \n",
       "\n",
       "     body_gyro_y_train  body_gyro_z_train  \n",
       "0             0.066014           0.022859  \n",
       "1             0.042699           0.010316  \n",
       "2             0.074850           0.013250  \n",
       "3             0.057320           0.017751  \n",
       "4             0.052343           0.002553  \n",
       "..                 ...                ...  \n",
       "123          -0.005166           0.007355  \n",
       "124          -0.001298           0.002669  \n",
       "125           0.001909          -0.002170  \n",
       "126          -0.000080          -0.005643  \n",
       "127          -0.000038          -0.001446  \n",
       "\n",
       "[128 rows x 9 columns]"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trainX.rename(columns = {\n",
    "    0:'total_acc_x_train',\n",
    "    1:'total_acc_y_train',\n",
    "    2:'total_acc_z_train',\n",
    "    3:'body_acc_x_train',\n",
    "    4:'body_acc_y_train',\n",
    "    5:'body_acc_z_train',\n",
    "    6:'body_gyro_x_train',\n",
    "    7:'body_gyro_y_train',\n",
    "    8:'body_gyro_z_train'\n",
    "}, inplace=True)\n",
    "df_trainX"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idea is that the model scans through the 9 values across 128 data points or time steps and gives out result as a single number."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An explanation of the function evaluate_model is as: \n",
    "We have ReLU (Rectified Linear Unit) as the activation function that outputs the input directly if it's positive, otherwise outputs zero.\n",
    "We set kernel size as 3 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alternative text](ConvTime.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
